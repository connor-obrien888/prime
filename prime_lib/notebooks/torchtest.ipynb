{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdde45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import RichProgressBar, Timer\n",
    "\n",
    "# Add the prime_torch file to the system path so we can import it\n",
    "import sys\n",
    "sys.path.append(\"/glade/u/home/cobrien/prime/prime_lib/primesw\")\n",
    "from data import SWDataset, SWDataModule\n",
    "from prime_torch import crps, SWRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e85bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.DataFrame([])\n",
    "test_dataframe['time'] = pd.date_range(\n",
    "    pd.to_datetime('20150902 00:00:00+0000'),\n",
    "    pd.to_datetime('20250101 00:00:00+0000'),\n",
    "    freq = '100s'\n",
    ")\n",
    "test_dataframe['a'] = np.arange(len(test_dataframe)) # Fake input\n",
    "test_dataframe['b'] = test_dataframe['a'] * 2 # Fake target\n",
    "test_dataframe['x_pos'] = np.arange(len(test_dataframe)) * 0.1\n",
    "test_dataframe['y_pos'] = np.arange(len(test_dataframe)) * 0.2\n",
    "test_dataframe['z_pos'] = np.arange(len(test_dataframe)) * 0.3\n",
    "test_dataframe.to_hdf(\"~/data/prime/test.h5\", key = 'lineartest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3447c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>x_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>z_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26784</th>\n",
       "      <td>2015-10-03 00:00:00+00:00</td>\n",
       "      <td>26784</td>\n",
       "      <td>53568</td>\n",
       "      <td>2678.4</td>\n",
       "      <td>5356.8</td>\n",
       "      <td>8035.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26785</th>\n",
       "      <td>2015-10-03 00:01:40+00:00</td>\n",
       "      <td>26785</td>\n",
       "      <td>53570</td>\n",
       "      <td>2678.5</td>\n",
       "      <td>5357.0</td>\n",
       "      <td>8035.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26786</th>\n",
       "      <td>2015-10-03 00:03:20+00:00</td>\n",
       "      <td>26786</td>\n",
       "      <td>53572</td>\n",
       "      <td>2678.6</td>\n",
       "      <td>5357.2</td>\n",
       "      <td>8035.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26787</th>\n",
       "      <td>2015-10-03 00:05:00+00:00</td>\n",
       "      <td>26787</td>\n",
       "      <td>53574</td>\n",
       "      <td>2678.7</td>\n",
       "      <td>5357.4</td>\n",
       "      <td>8036.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26788</th>\n",
       "      <td>2015-10-03 00:06:40+00:00</td>\n",
       "      <td>26788</td>\n",
       "      <td>53576</td>\n",
       "      <td>2678.8</td>\n",
       "      <td>5357.6</td>\n",
       "      <td>8036.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>2015-10-03 23:53:20+00:00</td>\n",
       "      <td>27644</td>\n",
       "      <td>55288</td>\n",
       "      <td>2764.4</td>\n",
       "      <td>5528.8</td>\n",
       "      <td>8293.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>2015-10-03 23:55:00+00:00</td>\n",
       "      <td>27645</td>\n",
       "      <td>55290</td>\n",
       "      <td>2764.5</td>\n",
       "      <td>5529.0</td>\n",
       "      <td>8293.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>2015-10-03 23:56:40+00:00</td>\n",
       "      <td>27646</td>\n",
       "      <td>55292</td>\n",
       "      <td>2764.6</td>\n",
       "      <td>5529.2</td>\n",
       "      <td>8293.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>2015-10-03 23:58:20+00:00</td>\n",
       "      <td>27647</td>\n",
       "      <td>55294</td>\n",
       "      <td>2764.7</td>\n",
       "      <td>5529.4</td>\n",
       "      <td>8294.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27648</th>\n",
       "      <td>2015-10-04 00:00:00+00:00</td>\n",
       "      <td>27648</td>\n",
       "      <td>55296</td>\n",
       "      <td>2764.8</td>\n",
       "      <td>5529.6</td>\n",
       "      <td>8294.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>865 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time      a      b   x_pos   y_pos   z_pos\n",
       "26784 2015-10-03 00:00:00+00:00  26784  53568  2678.4  5356.8  8035.2\n",
       "26785 2015-10-03 00:01:40+00:00  26785  53570  2678.5  5357.0  8035.5\n",
       "26786 2015-10-03 00:03:20+00:00  26786  53572  2678.6  5357.2  8035.8\n",
       "26787 2015-10-03 00:05:00+00:00  26787  53574  2678.7  5357.4  8036.1\n",
       "26788 2015-10-03 00:06:40+00:00  26788  53576  2678.8  5357.6  8036.4\n",
       "...                         ...    ...    ...     ...     ...     ...\n",
       "27644 2015-10-03 23:53:20+00:00  27644  55288  2764.4  5528.8  8293.2\n",
       "27645 2015-10-03 23:55:00+00:00  27645  55290  2764.5  5529.0  8293.5\n",
       "27646 2015-10-03 23:56:40+00:00  27646  55292  2764.6  5529.2  8293.8\n",
       "27647 2015-10-03 23:58:20+00:00  27647  55294  2764.7  5529.4  8294.1\n",
       "27648 2015-10-04 00:00:00+00:00  27648  55296  2764.8  5529.6  8294.4\n",
       "\n",
       "[865 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = ['20151003 00:00:00+0000', '20151004 00:00:00+0000']\n",
    "test_dataframe.loc[\n",
    "    (test_dataframe['time'] <= pd.to_datetime(bounds[1]))&\n",
    "    (test_dataframe['time'] >= pd.to_datetime(bounds[0])), :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3fcc77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-04 14:57:42.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mTrain dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-04 14:57:42.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1mValidation dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-04 14:57:42.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mTest dataloader is ready. Dataset size: 756\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trn_bounds = ['20151001 00:00:00+0000', '20151002 00:00:00+0000']\n",
    "tst_bounds = ['20151002 00:00:00+0000', '20151003 00:00:00+0000']\n",
    "val_bounds = ['20151003 00:00:00+0000', '20151004 00:00:00+0000']\n",
    "datamodule = SWDataModule(\n",
    "    target_features = ['b'],\n",
    "    input_features = ['a'],\n",
    "    position_features = ['x_pos', 'y_pos', 'z_pos'],\n",
    "    cadence = '100s',\n",
    "    window = 100,\n",
    "    stride = 10,\n",
    "    interp_frac = 0.1,\n",
    "    trn_bounds = trn_bounds,\n",
    "    val_bounds = val_bounds,\n",
    "    tst_bounds = tst_bounds,\n",
    "    datastore = \"~/data/prime/test.h5\",\n",
    "    key = \"lineartest\",\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ee3c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = SWRegressor(\n",
    "    in_dim = 1,\n",
    "    tar_dim = 1,\n",
    "    pos_dim = 3,\n",
    "    decoder_type = 'linear',\n",
    "    encoder_type = 'rnn',\n",
    "    lr_scheduler = 'cosine',\n",
    "    decoder_hidden_layers = [4],\n",
    "    encoder_hidden_dim = 4,\n",
    "    pos_encoding_size=4,\n",
    "    encoder_num_layers=1,\n",
    "    loss='mae'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e3732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator='cpu',\n",
    "    max_epochs=1,\n",
    "    callbacks = [Timer(), RichProgressBar()],\n",
    "    precision='16-true', #Lower the precision to not blow up memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed57139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-04 14:51:15.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m228\u001b[0m - \u001b[1mTrain dataloader is ready. Dataset size: 756\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-04 14:51:15.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1mValidation dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-04 14:51:15.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m264\u001b[0m - \u001b[1mTest dataloader is ready. Dataset size: 756\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ decoder │ LinearDecoder │    145 │ train │\n",
       "└───┴─────────┴───────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ decoder │ LinearDecoder │    145 │ train │\n",
       "└───┴─────────┴───────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 145                                                                                              \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 145                                                                                                  \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 6                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 145                                                                                              \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 145                                                                                                  \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 6                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e7aaa94a2a4e12a6f525c15e86006d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:484: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn\n",
       "shuffling off for val/test dataloaders.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:484: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn\n",
       "shuffling off for val/test dataloaders.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing \n",
       "the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing \n",
       "the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 150, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:560\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     52\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:598\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    591\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    592\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    593\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    594\u001b[39m     ckpt_path,\n\u001b[32m    595\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    596\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    597\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1011\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1008\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1016\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1053\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m   1052\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m   1055\u001b[39m         \u001b[38;5;28mself\u001b[39m.fit_loop.run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1082\u001b[39m, in \u001b[36mTrainer._run_sanity_check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1079\u001b[39m call._call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mon_sanity_check_start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1081\u001b[39m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1082\u001b[39m \u001b[43mval_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1084\u001b[39m call._call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mon_sanity_check_end\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1086\u001b[39m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     context_manager = torch.no_grad\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py:138\u001b[39m, in \u001b[36m_EvaluationLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    137\u001b[39m     dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     batch, batch_idx, dataloader_idx = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m previous_dataloader_idx != dataloader_idx:\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# the dataloader has changed, notify the logger connector\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m._store_dataloader_outputs()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    131\u001b[39m         \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batches\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mself\u001b[39m._start_profiler()\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ITERATOR_RETURN:\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n\u001b[32m    343\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/utilities/combined_loader.py:142\u001b[39m, in \u001b[36m_Sequential.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28mself\u001b[39m._use_next_iterator()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    628\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    629\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    633\u001b[39m         \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    634\u001b[39m         \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1345\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m-> \u001b[39m\u001b[32m1345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1371\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1369\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/_utils.py:694\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    691\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    692\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    693\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mTypeError\u001b[39m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 150, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_test = torch.rand((50,100,14))\n",
    "tar_test = torch.rand((50,1))\n",
    "pos_test = torch.rand((50,3))\n",
    "out_test = model.forward(in_test, pos_test)\n",
    "model.loss_fn(out_test, tar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b6fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 100, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17603eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt212gpu_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
