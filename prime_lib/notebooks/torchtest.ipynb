{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdde45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import RichProgressBar, Timer\n",
    "\n",
    "# Add the prime_torch file to the system path so we can import it\n",
    "import sys\n",
    "sys.path.append(\"/glade/u/home/cobrien/prime/prime_lib/primesw\")\n",
    "from data import SWDataset, SWDataModule\n",
    "from prime_torch import crps, SWRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e85bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.DataFrame([])\n",
    "test_dataframe['time'] = pd.date_range(\n",
    "    pd.to_datetime('20150902 00:00:00+0000'),\n",
    "    pd.to_datetime('20250101 00:00:00+0000'),\n",
    "    freq = '100s'\n",
    ")\n",
    "test_dataframe['a'] = np.arange(len(test_dataframe)) # Fake input\n",
    "test_dataframe['b'] = test_dataframe['a'] * 2 # Fake target\n",
    "test_dataframe['x_pos'] = np.arange(len(test_dataframe)) * 0.1\n",
    "test_dataframe['y_pos'] = np.arange(len(test_dataframe)) * 0.2\n",
    "test_dataframe['z_pos'] = np.arange(len(test_dataframe)) * 0.3\n",
    "test_dataframe.to_hdf(\"~/data/prime/test.h5\", key = 'lineartest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3447c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>x_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>z_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26784</th>\n",
       "      <td>2015-10-03 00:00:00+00:00</td>\n",
       "      <td>26784</td>\n",
       "      <td>53568</td>\n",
       "      <td>2678.4</td>\n",
       "      <td>5356.8</td>\n",
       "      <td>8035.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26785</th>\n",
       "      <td>2015-10-03 00:01:40+00:00</td>\n",
       "      <td>26785</td>\n",
       "      <td>53570</td>\n",
       "      <td>2678.5</td>\n",
       "      <td>5357.0</td>\n",
       "      <td>8035.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26786</th>\n",
       "      <td>2015-10-03 00:03:20+00:00</td>\n",
       "      <td>26786</td>\n",
       "      <td>53572</td>\n",
       "      <td>2678.6</td>\n",
       "      <td>5357.2</td>\n",
       "      <td>8035.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26787</th>\n",
       "      <td>2015-10-03 00:05:00+00:00</td>\n",
       "      <td>26787</td>\n",
       "      <td>53574</td>\n",
       "      <td>2678.7</td>\n",
       "      <td>5357.4</td>\n",
       "      <td>8036.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26788</th>\n",
       "      <td>2015-10-03 00:06:40+00:00</td>\n",
       "      <td>26788</td>\n",
       "      <td>53576</td>\n",
       "      <td>2678.8</td>\n",
       "      <td>5357.6</td>\n",
       "      <td>8036.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>2015-10-03 23:53:20+00:00</td>\n",
       "      <td>27644</td>\n",
       "      <td>55288</td>\n",
       "      <td>2764.4</td>\n",
       "      <td>5528.8</td>\n",
       "      <td>8293.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>2015-10-03 23:55:00+00:00</td>\n",
       "      <td>27645</td>\n",
       "      <td>55290</td>\n",
       "      <td>2764.5</td>\n",
       "      <td>5529.0</td>\n",
       "      <td>8293.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>2015-10-03 23:56:40+00:00</td>\n",
       "      <td>27646</td>\n",
       "      <td>55292</td>\n",
       "      <td>2764.6</td>\n",
       "      <td>5529.2</td>\n",
       "      <td>8293.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>2015-10-03 23:58:20+00:00</td>\n",
       "      <td>27647</td>\n",
       "      <td>55294</td>\n",
       "      <td>2764.7</td>\n",
       "      <td>5529.4</td>\n",
       "      <td>8294.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27648</th>\n",
       "      <td>2015-10-04 00:00:00+00:00</td>\n",
       "      <td>27648</td>\n",
       "      <td>55296</td>\n",
       "      <td>2764.8</td>\n",
       "      <td>5529.6</td>\n",
       "      <td>8294.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>865 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time      a      b   x_pos   y_pos   z_pos\n",
       "26784 2015-10-03 00:00:00+00:00  26784  53568  2678.4  5356.8  8035.2\n",
       "26785 2015-10-03 00:01:40+00:00  26785  53570  2678.5  5357.0  8035.5\n",
       "26786 2015-10-03 00:03:20+00:00  26786  53572  2678.6  5357.2  8035.8\n",
       "26787 2015-10-03 00:05:00+00:00  26787  53574  2678.7  5357.4  8036.1\n",
       "26788 2015-10-03 00:06:40+00:00  26788  53576  2678.8  5357.6  8036.4\n",
       "...                         ...    ...    ...     ...     ...     ...\n",
       "27644 2015-10-03 23:53:20+00:00  27644  55288  2764.4  5528.8  8293.2\n",
       "27645 2015-10-03 23:55:00+00:00  27645  55290  2764.5  5529.0  8293.5\n",
       "27646 2015-10-03 23:56:40+00:00  27646  55292  2764.6  5529.2  8293.8\n",
       "27647 2015-10-03 23:58:20+00:00  27647  55294  2764.7  5529.4  8294.1\n",
       "27648 2015-10-04 00:00:00+00:00  27648  55296  2764.8  5529.6  8294.4\n",
       "\n",
       "[865 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = ['20151003 00:00:00+0000', '20151004 00:00:00+0000']\n",
    "test_dataframe.loc[\n",
    "    (test_dataframe['time'] <= pd.to_datetime(bounds[1]))&\n",
    "    (test_dataframe['time'] >= pd.to_datetime(bounds[0])), :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3fcc77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-12 09:33:49.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mTrain dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-12 09:33:49.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1mValidation dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-12 09:33:49.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mTest dataloader is ready. Dataset size: 756\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trn_bounds = ['20151001 00:00:00+0000', '20151002 00:00:00+0000']\n",
    "tst_bounds = ['20151002 00:00:00+0000', '20151003 00:00:00+0000']\n",
    "val_bounds = ['20151003 00:00:00+0000', '20151004 00:00:00+0000']\n",
    "datamodule = SWDataModule(\n",
    "    target_features = ['b'],\n",
    "    input_features = ['a'],\n",
    "    position_features = ['x_pos', 'y_pos', 'z_pos'],\n",
    "    cadence = '100s',\n",
    "    window = 100,\n",
    "    stride = 10,\n",
    "    interp_frac = 0.1,\n",
    "    trn_bounds = trn_bounds,\n",
    "    val_bounds = val_bounds,\n",
    "    tst_bounds = tst_bounds,\n",
    "    datastore = \"~/data/prime/test.h5\",\n",
    "    key = \"lineartest\",\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ee3c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = SWRegressor(\n",
    "    in_dim = 1,\n",
    "    tar_dim = 1,\n",
    "    pos_dim = 3,\n",
    "    decoder_type = 'linear',\n",
    "    encoder_type = 'rnn',\n",
    "    lr_scheduler = 'cosine',\n",
    "    decoder_hidden_layers = [4],\n",
    "    encoder_hidden_dim = 4,\n",
    "    pos_encoding_size=4,\n",
    "    encoder_num_layers=1,\n",
    "    loss='mae'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e3732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator='cpu',\n",
    "    max_epochs=1,\n",
    "    callbacks = [Timer(), RichProgressBar()],\n",
    "    # precision='16-true', #Lower the precision to not blow up memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed57139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-12 09:33:50.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mTrain dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-12 09:33:50.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1mValidation dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-12 09:33:50.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mTest dataloader is ready. Dataset size: 756\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ encoder │ RecurrentEncoder │     28 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ decoder │ LinearDecoder    │    145 │ train │\n",
       "└───┴─────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ encoder │ RecurrentEncoder │     28 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ decoder │ LinearDecoder    │    145 │ train │\n",
       "└───┴─────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 173                                                                                              \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 173                                                                                                  \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 8                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 173                                                                                              \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 173                                                                                                  \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 8                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5ff447d7604716b6e49451724791f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing \n",
       "the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing \n",
       "the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve \n",
       "performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve \n",
       "performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310:\n",
       "The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower\n",
       "value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310:\n",
       "The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower\n",
       "value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb2730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_test = torch.rand((50,100,14))\n",
    "tar_test = torch.rand((50,1))\n",
    "pos_test = torch.rand((50,3))\n",
    "out_test = model.forward(in_test, pos_test)\n",
    "model.loss_fn(out_test, tar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b6fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 100, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17603eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt212gpu_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
