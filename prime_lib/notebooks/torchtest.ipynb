{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdde45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import RichProgressBar, Timer\n",
    "\n",
    "# Add the prime_torch file to the system path so we can import it\n",
    "import sys\n",
    "sys.path.append(\"/glade/u/home/cobrien/prime/prime_lib/primesw\")\n",
    "from data import SWDataset, SWDataModule\n",
    "from prime_torch import crps, SWRegressor\n",
    "\n",
    "DATAPATH = '~/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e85bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataframe = pd.DataFrame([])\n",
    "# test_dataframe['time'] = pd.date_range(\n",
    "#     pd.to_datetime('20150902 00:00:00+0000'),\n",
    "#     pd.to_datetime('20250101 00:00:00+0000'),\n",
    "#     freq = '100s'\n",
    "# )\n",
    "# test_dataframe['a'] = np.arange(len(test_dataframe)) # Fake input\n",
    "# test_dataframe['b'] = test_dataframe['a'] * 2 # Fake target\n",
    "# test_dataframe['x_pos'] = np.arange(len(test_dataframe)) * 0.1\n",
    "# test_dataframe['y_pos'] = np.arange(len(test_dataframe)) * 0.2\n",
    "# test_dataframe['z_pos'] = np.arange(len(test_dataframe)) * 0.3\n",
    "# test_dataframe.to_hdf(\"~/data/prime/test.h5\", key = 'lineartest')\n",
    "\n",
    "data = pd.read_hdf(DATAPATH + 'combined_data.h5', key = '1min_mms_wind')\n",
    "# list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68df5162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>probe</th>\n",
       "      <th>ratio_max_width</th>\n",
       "      <th>ratio_high_low</th>\n",
       "      <th>norm_Btot</th>\n",
       "      <th>small_energy_mean</th>\n",
       "      <th>large_energy_mean</th>\n",
       "      <th>temp_total</th>\n",
       "      <th>r_gse_x</th>\n",
       "      <th>r_gse_y</th>\n",
       "      <th>...</th>\n",
       "      <th>BGSE_0</th>\n",
       "      <th>BGSE_1</th>\n",
       "      <th>BGSE_2</th>\n",
       "      <th>PGSM_0</th>\n",
       "      <th>PGSM_1</th>\n",
       "      <th>PGSM_2</th>\n",
       "      <th>PGSE_0</th>\n",
       "      <th>PGSE_1</th>\n",
       "      <th>PGSE_2</th>\n",
       "      <th>stable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>783158</th>\n",
       "      <td>2022-12-06 11:22:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.099113</td>\n",
       "      <td>0.972141</td>\n",
       "      <td>0.090599</td>\n",
       "      <td>4.149168</td>\n",
       "      <td>4.033574</td>\n",
       "      <td>43.810337</td>\n",
       "      <td>70372.151606</td>\n",
       "      <td>121291.038427</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.115065</td>\n",
       "      <td>1.472905</td>\n",
       "      <td>-0.492083</td>\n",
       "      <td>220.266197</td>\n",
       "      <td>98.199184</td>\n",
       "      <td>-26.094267</td>\n",
       "      <td>220.266197</td>\n",
       "      <td>101.554920</td>\n",
       "      <td>3.253949</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783159</th>\n",
       "      <td>2022-12-06 11:23:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.099515</td>\n",
       "      <td>0.948516</td>\n",
       "      <td>0.091167</td>\n",
       "      <td>4.146450</td>\n",
       "      <td>3.932973</td>\n",
       "      <td>43.306786</td>\n",
       "      <td>70376.310770</td>\n",
       "      <td>121358.080725</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.138211</td>\n",
       "      <td>1.462516</td>\n",
       "      <td>-0.525947</td>\n",
       "      <td>220.267014</td>\n",
       "      <td>98.203819</td>\n",
       "      <td>-26.075378</td>\n",
       "      <td>220.267014</td>\n",
       "      <td>101.554546</td>\n",
       "      <td>3.254244</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783160</th>\n",
       "      <td>2022-12-06 11:24:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.951711</td>\n",
       "      <td>0.090902</td>\n",
       "      <td>4.122525</td>\n",
       "      <td>3.923451</td>\n",
       "      <td>41.421787</td>\n",
       "      <td>70380.430313</td>\n",
       "      <td>121425.050925</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.107340</td>\n",
       "      <td>1.537073</td>\n",
       "      <td>-0.616459</td>\n",
       "      <td>220.267830</td>\n",
       "      <td>98.208530</td>\n",
       "      <td>-26.056184</td>\n",
       "      <td>220.267830</td>\n",
       "      <td>101.554169</td>\n",
       "      <td>3.254539</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783161</th>\n",
       "      <td>2022-12-06 11:25:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.097986</td>\n",
       "      <td>0.933466</td>\n",
       "      <td>0.090189</td>\n",
       "      <td>4.155700</td>\n",
       "      <td>3.879203</td>\n",
       "      <td>41.902737</td>\n",
       "      <td>70384.521589</td>\n",
       "      <td>121491.969787</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.101038</td>\n",
       "      <td>1.556031</td>\n",
       "      <td>-0.626554</td>\n",
       "      <td>220.268639</td>\n",
       "      <td>98.213322</td>\n",
       "      <td>-26.036689</td>\n",
       "      <td>220.268639</td>\n",
       "      <td>101.553791</td>\n",
       "      <td>3.254835</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783162</th>\n",
       "      <td>2022-12-06 11:26:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.097573</td>\n",
       "      <td>0.931189</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>4.113208</td>\n",
       "      <td>3.830173</td>\n",
       "      <td>41.628290</td>\n",
       "      <td>70388.573237</td>\n",
       "      <td>121558.816731</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.058907</td>\n",
       "      <td>1.623733</td>\n",
       "      <td>-0.725471</td>\n",
       "      <td>220.269447</td>\n",
       "      <td>98.218189</td>\n",
       "      <td>-26.016889</td>\n",
       "      <td>220.269447</td>\n",
       "      <td>101.553413</td>\n",
       "      <td>3.255130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905237</th>\n",
       "      <td>2023-06-01 14:17:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.139900</td>\n",
       "      <td>1.053616</td>\n",
       "      <td>0.119622</td>\n",
       "      <td>3.972942</td>\n",
       "      <td>4.185954</td>\n",
       "      <td>84.981760</td>\n",
       "      <td>6950.367742</td>\n",
       "      <td>-140112.240351</td>\n",
       "      <td>...</td>\n",
       "      <td>3.125178</td>\n",
       "      <td>-1.409303</td>\n",
       "      <td>2.854743</td>\n",
       "      <td>227.914986</td>\n",
       "      <td>103.248070</td>\n",
       "      <td>5.631277</td>\n",
       "      <td>227.914986</td>\n",
       "      <td>103.337818</td>\n",
       "      <td>3.629431</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905238</th>\n",
       "      <td>2023-06-01 14:18:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.137356</td>\n",
       "      <td>1.000378</td>\n",
       "      <td>0.118647</td>\n",
       "      <td>4.006738</td>\n",
       "      <td>4.008254</td>\n",
       "      <td>68.139725</td>\n",
       "      <td>6977.824836</td>\n",
       "      <td>-140057.052744</td>\n",
       "      <td>...</td>\n",
       "      <td>3.847021</td>\n",
       "      <td>-0.835190</td>\n",
       "      <td>2.378296</td>\n",
       "      <td>227.915802</td>\n",
       "      <td>103.244072</td>\n",
       "      <td>5.696580</td>\n",
       "      <td>227.915802</td>\n",
       "      <td>103.337395</td>\n",
       "      <td>3.629699</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905239</th>\n",
       "      <td>2023-06-01 14:19:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.140705</td>\n",
       "      <td>0.994115</td>\n",
       "      <td>0.120214</td>\n",
       "      <td>4.052110</td>\n",
       "      <td>4.028265</td>\n",
       "      <td>69.984500</td>\n",
       "      <td>7005.280935</td>\n",
       "      <td>-140001.818190</td>\n",
       "      <td>...</td>\n",
       "      <td>4.275983</td>\n",
       "      <td>-0.737198</td>\n",
       "      <td>1.802373</td>\n",
       "      <td>227.916618</td>\n",
       "      <td>103.240017</td>\n",
       "      <td>5.762163</td>\n",
       "      <td>227.916618</td>\n",
       "      <td>103.336967</td>\n",
       "      <td>3.629966</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905240</th>\n",
       "      <td>2023-06-01 14:20:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.144459</td>\n",
       "      <td>1.117512</td>\n",
       "      <td>0.129521</td>\n",
       "      <td>3.667746</td>\n",
       "      <td>4.098751</td>\n",
       "      <td>95.530670</td>\n",
       "      <td>7032.735244</td>\n",
       "      <td>-139946.518416</td>\n",
       "      <td>...</td>\n",
       "      <td>4.273108</td>\n",
       "      <td>-1.447723</td>\n",
       "      <td>1.191945</td>\n",
       "      <td>227.917427</td>\n",
       "      <td>103.235905</td>\n",
       "      <td>5.828058</td>\n",
       "      <td>227.917427</td>\n",
       "      <td>103.336544</td>\n",
       "      <td>3.630233</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905241</th>\n",
       "      <td>2023-06-01 14:21:00+00:00</td>\n",
       "      <td>mms1</td>\n",
       "      <td>0.146449</td>\n",
       "      <td>1.205363</td>\n",
       "      <td>0.126815</td>\n",
       "      <td>3.607584</td>\n",
       "      <td>4.348447</td>\n",
       "      <td>110.716120</td>\n",
       "      <td>7060.188479</td>\n",
       "      <td>-139891.171723</td>\n",
       "      <td>...</td>\n",
       "      <td>4.181842</td>\n",
       "      <td>-1.774199</td>\n",
       "      <td>1.174838</td>\n",
       "      <td>227.918243</td>\n",
       "      <td>103.231728</td>\n",
       "      <td>5.894270</td>\n",
       "      <td>227.918243</td>\n",
       "      <td>103.336121</td>\n",
       "      <td>3.630501</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49443 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Epoch probe  ratio_max_width  ratio_high_low  \\\n",
       "783158 2022-12-06 11:22:00+00:00  mms1         0.099113        0.972141   \n",
       "783159 2022-12-06 11:23:00+00:00  mms1         0.099515        0.948516   \n",
       "783160 2022-12-06 11:24:00+00:00  mms1         0.096700        0.951711   \n",
       "783161 2022-12-06 11:25:00+00:00  mms1         0.097986        0.933466   \n",
       "783162 2022-12-06 11:26:00+00:00  mms1         0.097573        0.931189   \n",
       "...                          ...   ...              ...             ...   \n",
       "905237 2023-06-01 14:17:00+00:00  mms1         0.139900        1.053616   \n",
       "905238 2023-06-01 14:18:00+00:00  mms1         0.137356        1.000378   \n",
       "905239 2023-06-01 14:19:00+00:00  mms1         0.140705        0.994115   \n",
       "905240 2023-06-01 14:20:00+00:00  mms1         0.144459        1.117512   \n",
       "905241 2023-06-01 14:21:00+00:00  mms1         0.146449        1.205363   \n",
       "\n",
       "        norm_Btot  small_energy_mean  large_energy_mean  temp_total  \\\n",
       "783158   0.090599           4.149168           4.033574   43.810337   \n",
       "783159   0.091167           4.146450           3.932973   43.306786   \n",
       "783160   0.090902           4.122525           3.923451   41.421787   \n",
       "783161   0.090189           4.155700           3.879203   41.902737   \n",
       "783162   0.089900           4.113208           3.830173   41.628290   \n",
       "...           ...                ...                ...         ...   \n",
       "905237   0.119622           3.972942           4.185954   84.981760   \n",
       "905238   0.118647           4.006738           4.008254   68.139725   \n",
       "905239   0.120214           4.052110           4.028265   69.984500   \n",
       "905240   0.129521           3.667746           4.098751   95.530670   \n",
       "905241   0.126815           3.607584           4.348447  110.716120   \n",
       "\n",
       "             r_gse_x        r_gse_y  ...    BGSE_0    BGSE_1    BGSE_2  \\\n",
       "783158  70372.151606  121291.038427  ... -4.115065  1.472905 -0.492083   \n",
       "783159  70376.310770  121358.080725  ... -4.138211  1.462516 -0.525947   \n",
       "783160  70380.430313  121425.050925  ... -4.107340  1.537073 -0.616459   \n",
       "783161  70384.521589  121491.969787  ... -4.101038  1.556031 -0.626554   \n",
       "783162  70388.573237  121558.816731  ... -4.058907  1.623733 -0.725471   \n",
       "...              ...            ...  ...       ...       ...       ...   \n",
       "905237   6950.367742 -140112.240351  ...  3.125178 -1.409303  2.854743   \n",
       "905238   6977.824836 -140057.052744  ...  3.847021 -0.835190  2.378296   \n",
       "905239   7005.280935 -140001.818190  ...  4.275983 -0.737198  1.802373   \n",
       "905240   7032.735244 -139946.518416  ...  4.273108 -1.447723  1.191945   \n",
       "905241   7060.188479 -139891.171723  ...  4.181842 -1.774199  1.174838   \n",
       "\n",
       "            PGSM_0      PGSM_1     PGSM_2      PGSE_0      PGSE_1    PGSE_2  \\\n",
       "783158  220.266197   98.199184 -26.094267  220.266197  101.554920  3.253949   \n",
       "783159  220.267014   98.203819 -26.075378  220.267014  101.554546  3.254244   \n",
       "783160  220.267830   98.208530 -26.056184  220.267830  101.554169  3.254539   \n",
       "783161  220.268639   98.213322 -26.036689  220.268639  101.553791  3.254835   \n",
       "783162  220.269447   98.218189 -26.016889  220.269447  101.553413  3.255130   \n",
       "...            ...         ...        ...         ...         ...       ...   \n",
       "905237  227.914986  103.248070   5.631277  227.914986  103.337818  3.629431   \n",
       "905238  227.915802  103.244072   5.696580  227.915802  103.337395  3.629699   \n",
       "905239  227.916618  103.240017   5.762163  227.916618  103.336967  3.629966   \n",
       "905240  227.917427  103.235905   5.828058  227.917427  103.336544  3.630233   \n",
       "905241  227.918243  103.231728   5.894270  227.918243  103.336121  3.630501   \n",
       "\n",
       "        stable  \n",
       "783158     1.0  \n",
       "783159     1.0  \n",
       "783160     1.0  \n",
       "783161     1.0  \n",
       "783162     1.0  \n",
       "...        ...  \n",
       "905237     1.0  \n",
       "905238     1.0  \n",
       "905239     1.0  \n",
       "905240     1.0  \n",
       "905241     1.0  \n",
       "\n",
       "[49443 rows x 107 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data['modified_named_label'] == 'solar wind')&(data['stable'] == 1), :].iloc[int(0.8*247215):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048af77d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SWDataModule.__init__() got an unexpected keyword argument 'region'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m tst_bounds = [\u001b[33m'\u001b[39m\u001b[33m20211217 04:34:00+0000\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m20221206 11:21:00+0000\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     34\u001b[39m val_bounds = [\u001b[33m'\u001b[39m\u001b[33m20221206 11:22:00+0000\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m20230601 14:21:00+0000\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m datamodule = \u001b[43mSWDataModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_features\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_features\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msolar wind\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcadence\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m100s\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterp_frac\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrn_bounds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_bounds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtst_bounds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtst_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatastore\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m~/data/combined_data.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1min_mms_wind\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m datamodule.setup()\n",
      "\u001b[31mTypeError\u001b[39m: SWDataModule.__init__() got an unexpected keyword argument 'region'"
     ]
    }
   ],
   "source": [
    "target_features = [\n",
    "    'mms1_dis_bulkv_gse_fast_0', # V GSE X\n",
    "    'mms1_dis_bulkv_gse_fast_1', # V GSE Y\n",
    "    'mms1_dis_bulkv_gse_fast_2', # V GSE Z\n",
    "    # 'mms1_dis_numberdensity_fast', # Ni\n",
    "    # 'mms1_dis_temppara_fast', # Ti parallel to B\n",
    "    # 'mms1_dis_tempperp_fast', # Ti perpendicular to B\n",
    "    'mms1_des_numberdensity_fast', # Ne\n",
    "    'mms1_fgm_b_gse_srvy_l2_0', # B GSE X\n",
    "    'mms1_fgm_b_gse_srvy_l2_1', # B GSE Y\n",
    "    'mms1_fgm_b_gse_srvy_l2_2', # B GSE Z\n",
    "]\n",
    "input_features = [\n",
    "    'Np', # Ni\n",
    "    'V_GSE_0', # V GSE X\n",
    "    'V_GSE_1', # V GSE Y\n",
    "    'V_GSE_2', # V GSE Z\n",
    "    'THERMAL_SPD', # Vth\n",
    "    'BGSE_0', # B GSE X\n",
    "    'BGSE_1', # B GSE Y\n",
    "    'BGSE_2', # B GSE Z\n",
    "    'PGSE_0', # Wind Position GSE X\n",
    "    'PGSE_1', # Wind Position GSE Y\n",
    "    'PGSE_2', # Wind Position GSE Z\n",
    "]\n",
    "position_features = [\n",
    "    'mms1_mec_r_gse_0', # MMS Position GSE X\n",
    "    'mms1_mec_r_gse_1', # MMS Position GSE Y\n",
    "    'mms1_mec_r_gse_2', # MMS Position GSE Z\n",
    "]\n",
    "\n",
    "trn_bounds = ['20151007 12:08:00+0000', '20211217 04:33:00+0000']\n",
    "tst_bounds = ['20211217 04:34:00+0000', '20221206 11:21:00+0000']\n",
    "val_bounds = ['20221206 11:22:00+0000', '20230601 14:21:00+0000']\n",
    "datamodule = SWDataModule(\n",
    "    target_features = target_features,\n",
    "    input_features = input_features,\n",
    "    position_features = position_features,\n",
    "    region = 'solar wind',\n",
    "    cadence = '100s',\n",
    "    window = 100,\n",
    "    stride = 10,\n",
    "    interp_frac = 0.1,\n",
    "    trn_bounds = trn_bounds,\n",
    "    val_bounds = val_bounds,\n",
    "    tst_bounds = tst_bounds,\n",
    "    datastore = \"~/data/combined_data.h5\",\n",
    "    key = \"1min_mms_wind\",\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = SWRegressor(\n",
    "    in_dim = len(input_features),\n",
    "    tar_dim = len(target_features),\n",
    "    pos_dim = len(position_features),\n",
    "    decoder_type = 'linear',\n",
    "    encoder_type = 'rnn',\n",
    "    lr_scheduler = 'cosine',\n",
    "    decoder_hidden_layers = [4],\n",
    "    encoder_hidden_dim = 4,\n",
    "    pos_encoding_size=4,\n",
    "    encoder_num_layers=1,\n",
    "    loss='mae'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(\n",
    "    save_dir = \"~/data/prime/tensorboard_logs\",\n",
    "    name = 'test_model',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator='cpu',\n",
    "    max_epochs=1,\n",
    "    callbacks = [\n",
    "        Timer(), \n",
    "        RichProgressBar(),\n",
    "        # ModelCheckpoint(),\n",
    "        ],\n",
    "    logger = logger,\n",
    "    # precision='16-true', #Lower the precision to not blow up memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed57139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-25 08:26:33.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m241\u001b[0m - \u001b[1mTrain dataloader is ready. Dataset size: 148220\u001b[0m\n",
      "\u001b[32m2025-09-25 08:26:40.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m259\u001b[0m - \u001b[1mValidation dataloader is ready. Dataset size: 49334\u001b[0m\n",
      "\u001b[32m2025-09-25 08:26:48.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mTest dataloader is ready. Dataset size: 49334\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ decoder │ LinearDecoder │    175 │ train │\n",
       "└───┴─────────┴───────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ decoder │ LinearDecoder │    175 │ train │\n",
       "└───┴─────────┴───────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 175                                                                                              \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 175                                                                                                  \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 6                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 175                                                                                              \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 175                                                                                                  \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 6                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e387ef3d1894485c884339b95cf58fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing \n",
       "the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing \n",
       "the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve \n",
       "performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve \n",
       "performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'RecurrentEncoder' object has no attribute 'named_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:560\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     52\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:598\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    591\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    592\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    593\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    594\u001b[39m     ckpt_path,\n\u001b[32m    595\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    596\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    597\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1011\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1008\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1016\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1055\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1053\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_sanity_check()\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.state\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end()\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_epoch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:152\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:348\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_batch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    347\u001b[39m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m         batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    350\u001b[39m         batch_output = \u001b[38;5;28mself\u001b[39m.manual_optimization.run(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         closure()\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim_progress.optimizer.step.increment_ready()\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[32m    280\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim_progress.optimizer.step.increment_completed()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:177\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m pl_module._current_fx_name = hook_name\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    180\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1366\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimizer_step\u001b[39m(\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1337\u001b[39m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1340\u001b[39m     optimizer_closure: Optional[Callable[[], Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1341\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1342\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1343\u001b[39m \u001b[33;03m    the optimizer.\u001b[39;00m\n\u001b[32m   1344\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1364\u001b[39m \n\u001b[32m   1365\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1366\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[33m\"\u001b[39m\u001b[33mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:68\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m instance._step_count += \u001b[32m1\u001b[39m\n\u001b[32m     67\u001b[39m wrapped = func.\u001b[34m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    369\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    370\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    371\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m'\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     75\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/optim/adam.py:143\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n\u001b[32m    146\u001b[39m     params_with_grad = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:110\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mhook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    109\u001b[39m closure_result = closure()\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_after_closure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:88\u001b[39m, in \u001b[36mPrecision._after_closure\u001b[39m\u001b[34m(self, model, optimizer)\u001b[39m\n\u001b[32m     86\u001b[39m trainer = model.trainer\n\u001b[32m     87\u001b[39m call._call_callback_hooks(trainer, \u001b[33m\"\u001b[39m\u001b[33mon_before_optimizer_step\u001b[39m\u001b[33m\"\u001b[39m, optimizer)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_before_optimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m._clip_gradients(\n\u001b[32m     90\u001b[39m     model,\n\u001b[32m     91\u001b[39m     optimizer,\n\u001b[32m     92\u001b[39m     trainer.gradient_clip_val,\n\u001b[32m     93\u001b[39m     gradient_clip_algorithm=trainer.gradient_clip_algorithm,\n\u001b[32m     94\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:177\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m pl_module._current_fx_name = hook_name\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    180\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime/prime_lib/primesw/prime_torch.py:207\u001b[39m, in \u001b[36mSWRegressor.on_before_optimizer_step\u001b[39m\u001b[34m(self, optimizer)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_before_optimizer_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer):\n\u001b[32m    205\u001b[39m     \u001b[38;5;66;03m# Compute the 2-norm for each layer\u001b[39;00m\n\u001b[32m    206\u001b[39m     \u001b[38;5;66;03m# If using mixed precision, the gradients are already unscaled here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     norms = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutilities\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28mself\u001b[39m.log_dict(norms)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/utilities/grads.py:47\u001b[39m, in \u001b[36mgrad_norm\u001b[39m\u001b[34m(module, norm_type, group_separator)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m norm_type <= \u001b[32m0\u001b[39m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`norm_type` must be a positive number or \u001b[39m\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m (infinity norm). Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m norms = {\n\u001b[32m     46\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgrad_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_norm\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup_separator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: p.grad.data.norm(norm_type)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnamed_parameters\u001b[49m()\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     49\u001b[39m }\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m norms:\n\u001b[32m     51\u001b[39m     total_norm = torch.tensor(\u001b[38;5;28mlist\u001b[39m(norms.values())).norm(norm_type)\n",
      "\u001b[31mAttributeError\u001b[39m: 'RecurrentEncoder' object has no attribute 'named_parameters'"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_test = torch.rand((50,100,14))\n",
    "tar_test = torch.rand((50,1))\n",
    "pos_test = torch.rand((50,3))\n",
    "out_test = model.forward(in_test, pos_test)\n",
    "model.loss_fn(out_test, tar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b6fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 100, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17603eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt212gpu_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
