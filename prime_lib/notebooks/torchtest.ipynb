{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bdde45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import RichProgressBar, Timer, ModelCheckpoint\n",
    "\n",
    "# Add the prime_torch file to the system path so we can import it\n",
    "import sys\n",
    "sys.path.append(\"/glade/u/home/cobrien/prime/prime_lib/primesw\")\n",
    "from data import SWDataset, SWDataModule\n",
    "from prime_torch import crps, SWRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e85bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.DataFrame([])\n",
    "test_dataframe['time'] = pd.date_range(\n",
    "    pd.to_datetime('20150902 00:00:00+0000'),\n",
    "    pd.to_datetime('20250101 00:00:00+0000'),\n",
    "    freq = '100s'\n",
    ")\n",
    "test_dataframe['a'] = np.arange(len(test_dataframe)) # Fake input\n",
    "test_dataframe['b'] = test_dataframe['a'] * 2 # Fake target\n",
    "test_dataframe['x_pos'] = np.arange(len(test_dataframe)) * 0.1\n",
    "test_dataframe['y_pos'] = np.arange(len(test_dataframe)) * 0.2\n",
    "test_dataframe['z_pos'] = np.arange(len(test_dataframe)) * 0.3\n",
    "test_dataframe.to_hdf(\"~/data/prime/test.h5\", key = 'lineartest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3447c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>x_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>z_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26784</th>\n",
       "      <td>2015-10-03 00:00:00+00:00</td>\n",
       "      <td>26784</td>\n",
       "      <td>53568</td>\n",
       "      <td>2678.4</td>\n",
       "      <td>5356.8</td>\n",
       "      <td>8035.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26785</th>\n",
       "      <td>2015-10-03 00:01:40+00:00</td>\n",
       "      <td>26785</td>\n",
       "      <td>53570</td>\n",
       "      <td>2678.5</td>\n",
       "      <td>5357.0</td>\n",
       "      <td>8035.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26786</th>\n",
       "      <td>2015-10-03 00:03:20+00:00</td>\n",
       "      <td>26786</td>\n",
       "      <td>53572</td>\n",
       "      <td>2678.6</td>\n",
       "      <td>5357.2</td>\n",
       "      <td>8035.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26787</th>\n",
       "      <td>2015-10-03 00:05:00+00:00</td>\n",
       "      <td>26787</td>\n",
       "      <td>53574</td>\n",
       "      <td>2678.7</td>\n",
       "      <td>5357.4</td>\n",
       "      <td>8036.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26788</th>\n",
       "      <td>2015-10-03 00:06:40+00:00</td>\n",
       "      <td>26788</td>\n",
       "      <td>53576</td>\n",
       "      <td>2678.8</td>\n",
       "      <td>5357.6</td>\n",
       "      <td>8036.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>2015-10-03 23:53:20+00:00</td>\n",
       "      <td>27644</td>\n",
       "      <td>55288</td>\n",
       "      <td>2764.4</td>\n",
       "      <td>5528.8</td>\n",
       "      <td>8293.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>2015-10-03 23:55:00+00:00</td>\n",
       "      <td>27645</td>\n",
       "      <td>55290</td>\n",
       "      <td>2764.5</td>\n",
       "      <td>5529.0</td>\n",
       "      <td>8293.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>2015-10-03 23:56:40+00:00</td>\n",
       "      <td>27646</td>\n",
       "      <td>55292</td>\n",
       "      <td>2764.6</td>\n",
       "      <td>5529.2</td>\n",
       "      <td>8293.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>2015-10-03 23:58:20+00:00</td>\n",
       "      <td>27647</td>\n",
       "      <td>55294</td>\n",
       "      <td>2764.7</td>\n",
       "      <td>5529.4</td>\n",
       "      <td>8294.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27648</th>\n",
       "      <td>2015-10-04 00:00:00+00:00</td>\n",
       "      <td>27648</td>\n",
       "      <td>55296</td>\n",
       "      <td>2764.8</td>\n",
       "      <td>5529.6</td>\n",
       "      <td>8294.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>865 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           time      a      b   x_pos   y_pos   z_pos\n",
       "26784 2015-10-03 00:00:00+00:00  26784  53568  2678.4  5356.8  8035.2\n",
       "26785 2015-10-03 00:01:40+00:00  26785  53570  2678.5  5357.0  8035.5\n",
       "26786 2015-10-03 00:03:20+00:00  26786  53572  2678.6  5357.2  8035.8\n",
       "26787 2015-10-03 00:05:00+00:00  26787  53574  2678.7  5357.4  8036.1\n",
       "26788 2015-10-03 00:06:40+00:00  26788  53576  2678.8  5357.6  8036.4\n",
       "...                         ...    ...    ...     ...     ...     ...\n",
       "27644 2015-10-03 23:53:20+00:00  27644  55288  2764.4  5528.8  8293.2\n",
       "27645 2015-10-03 23:55:00+00:00  27645  55290  2764.5  5529.0  8293.5\n",
       "27646 2015-10-03 23:56:40+00:00  27646  55292  2764.6  5529.2  8293.8\n",
       "27647 2015-10-03 23:58:20+00:00  27647  55294  2764.7  5529.4  8294.1\n",
       "27648 2015-10-04 00:00:00+00:00  27648  55296  2764.8  5529.6  8294.4\n",
       "\n",
       "[865 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = ['20151003 00:00:00+0000', '20151004 00:00:00+0000']\n",
    "test_dataframe.loc[\n",
    "    (test_dataframe['time'] <= pd.to_datetime(bounds[1]))&\n",
    "    (test_dataframe['time'] >= pd.to_datetime(bounds[0])), :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3fcc77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-12 13:50:50.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mTrain dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-12 13:50:50.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1mValidation dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-12 13:50:50.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mTest dataloader is ready. Dataset size: 756\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trn_bounds = ['20151001 00:00:00+0000', '20151002 00:00:00+0000']\n",
    "tst_bounds = ['20151002 00:00:00+0000', '20151003 00:00:00+0000']\n",
    "val_bounds = ['20151003 00:00:00+0000', '20151004 00:00:00+0000']\n",
    "datamodule = SWDataModule(\n",
    "    target_features = ['b'],\n",
    "    input_features = ['a'],\n",
    "    position_features = ['x_pos', 'y_pos', 'z_pos'],\n",
    "    cadence = '100s',\n",
    "    window = 100,\n",
    "    stride = 10,\n",
    "    interp_frac = 0.1,\n",
    "    trn_bounds = trn_bounds,\n",
    "    val_bounds = val_bounds,\n",
    "    tst_bounds = tst_bounds,\n",
    "    datastore = \"~/data/prime/test.h5\",\n",
    "    key = \"lineartest\",\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ee3c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = SWRegressor(\n",
    "    in_dim = 1,\n",
    "    tar_dim = 1,\n",
    "    pos_dim = 3,\n",
    "    decoder_type = 'linear',\n",
    "    encoder_type = 'rnn',\n",
    "    lr_scheduler = 'cosine',\n",
    "    decoder_hidden_layers = [4],\n",
    "    encoder_hidden_dim = 4,\n",
    "    pos_encoding_size=4,\n",
    "    encoder_num_layers=1,\n",
    "    loss='mae'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e3732c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Neither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\nRequirement 'tensorboardX' not met. HINT: Try running `pip install -U 'tensorboardX'`\nRequirement 'tensorboard' not met. HINT: Try running `pip install -U 'tensorboard'`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m logger = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloggers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensorBoardLogger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m~/data/prime/tensorboard_logs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest_model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m trainer = pl.Trainer(\n\u001b[32m      6\u001b[39m     accelerator=\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     max_epochs=\u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# precision='16-true', #Lower the precision to not blow up memory\u001b[39;00m\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loggers/tensorboard.py:96\u001b[39m, in \u001b[36mTensorBoardLogger.__init__\u001b[39m\u001b[34m(self, save_dir, name, version, log_graph, default_hp_metric, prefix, sub_dir, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     86\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     87\u001b[39m     save_dir: _PATH,\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m     **kwargs: Any,\n\u001b[32m     95\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdefault_hp_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_hp_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43msub_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m log_graph \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _TENSORBOARD_AVAILABLE:\n\u001b[32m    106\u001b[39m         rank_zero_warn(\n\u001b[32m    107\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou set `TensorBoardLogger(log_graph=True)` but `tensorboard` is not available.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    108\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_TENSORBOARD_AVAILABLE)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/fabric/loggers/tensorboard.py:93\u001b[39m, in \u001b[36mTensorBoardLogger.__init__\u001b[39m\u001b[34m(self, root_dir, name, version, default_hp_metric, prefix, sub_dir, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     84\u001b[39m     root_dir: _PATH,\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m     **kwargs: Any,\n\u001b[32m     91\u001b[39m ):\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _TENSORBOARD_AVAILABLE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _TENSORBOARDX_AVAILABLE:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m     94\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNeither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_TENSORBOARDX_AVAILABLE)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_TENSORBOARD_AVAILABLE)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m         )\n\u001b[32m     97\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m     98\u001b[39m     root_dir = os.fspath(root_dir)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: Neither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\nRequirement 'tensorboardX' not met. HINT: Try running `pip install -U 'tensorboardX'`\nRequirement 'tensorboard' not met. HINT: Try running `pip install -U 'tensorboard'`"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(\n",
    "    save_dir = \"~/data/prime/tensorboard_logs\",\n",
    "    name = 'test_model',\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='cpu',\n",
    "    max_epochs=1,\n",
    "    callbacks = [\n",
    "        Timer(), \n",
    "        RichProgressBar(),\n",
    "        # ModelCheckpoint(),\n",
    "        ],\n",
    "    logger = logger,\n",
    "    # precision='16-true', #Lower the precision to not blow up memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed57139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-12 09:33:50.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mTrain dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-12 09:33:50.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1mValidation dataloader is ready. Dataset size: 756\u001b[0m\n",
      "\u001b[32m2025-09-12 09:33:50.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mTest dataloader is ready. Dataset size: 756\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ encoder │ RecurrentEncoder │     28 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ decoder │ LinearDecoder    │    145 │ train │\n",
       "└───┴─────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ encoder │ RecurrentEncoder │     28 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ decoder │ LinearDecoder    │    145 │ train │\n",
       "└───┴─────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 173                                                                                              \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 173                                                                                                  \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 8                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 173                                                                                              \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 173                                                                                                  \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 8                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5ff447d7604716b6e49451724791f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing \n",
       "the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing \n",
       "the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve \n",
       "performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve \n",
       "performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310:\n",
       "The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower\n",
       "value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/glade/work/cobrien/conda-envs/pt212gpu_conda/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310:\n",
       "The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower\n",
       "value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb2730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_test = torch.rand((50,100,14))\n",
    "tar_test = torch.rand((50,1))\n",
    "pos_test = torch.rand((50,3))\n",
    "out_test = model.forward(in_test, pos_test)\n",
    "model.loss_fn(out_test, tar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b6fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 100, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17603eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt212gpu_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
